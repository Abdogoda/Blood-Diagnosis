import os
import json
from pathlib import Path
import warnings

# Suppress warnings
warnings.filterwarnings('ignore', category=UserWarning, module='pytorch_tabnet')
warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')
warnings.filterwarnings('ignore', message='.*InconsistentVersionWarning.*')

import numpy as np
import pandas as pd
import joblib
from pytorch_tabnet.tab_model import TabNetClassifier


# =================== Configuration ===================
# Get the directory where this file is located
CURRENT_DIR = Path(__file__).parent

# Model file paths
MODEL_PATH   = str(CURRENT_DIR / "tabnet_anemia_model.zip")
SCALER_PATH  = str(CURRENT_DIR / "scaler.pkl")
FEATURES_PTH = str(CURRENT_DIR / "used_features.json")

# Column name aliases for flexible input
ALIASES = {
    'TLC':  ['tlc', 'wbc', 'white blood cells', 'whitebloodcells', 'w.b.c'],
    'PCV':  ['pcv', 'hct', 'hematocrit'],
    'RBC':  ['rbc', 'red blood cells', 'redbloodcells'],
    'HGB':  ['hgb', 'hb', 'hemoglobin', 'haemoglobin'],
    'MCV':  ['mcv'],
    'MCH':  ['mch'],
    'MCHC': ['mchc'],
    'PLT':  ['plt', 'platelets', 'platelet', 'platelet count'],
    'RDW':  ['rdw', 'rdw-cv', 'rdw_cv', 'rdwcv', 'rdw_sd', 'rdwsd'],
    'Age':  ['age', 'years', 'age (y)'],
    'Sex':  ['sex', 'gender', 'm/f', 'male/female'],
    'ID':   ['id', 'sample id', 'sampleid', 'record id', 'patient id', 'no'],
}


# =================== Helper Functions ===================

def norm(s: str) -> str:
    return str(s).strip().lower().replace(' ', '').replace('.', '').replace('-', '').replace('_', '')


def build_rename_map(df_columns):
    rename_map = {}
    for std_name, variants in ALIASES.items():
        for v in variants:
            v_key = norm(v)
            for col in df_columns:
                if norm(col) == v_key:
                    rename_map[col] = std_name
                    break
            if std_name in rename_map.values():
                break
    return rename_map


def normalize_sex_column(series: pd.Series) -> pd.Series:
    if series.dtype == 'object':
        mapped = series.astype(str).str.strip().str.upper().map({
            'F': 0, 'FEMALE': 0, '0': 0,
            'M': 1, 'MALE': 1, '1': 1,
        })
        return pd.to_numeric(mapped, errors='coerce')
    else:
        vals = pd.Series(series.dropna().unique())
        if set(vals) == {0, 1}:
            return series
        if set(vals) == {1, 2}:
            return series.astype(float) - 1
        return pd.to_numeric(series, errors='coerce')


def prepare_dataframe_for_inference(raw_df: pd.DataFrame, used_features, allow_hgb_heuristic: bool = True) -> pd.DataFrame:
    df = raw_df.copy()
    
    # Rename columns
    df = df.rename(columns=build_rename_map(df.columns))
    
    # Normalize Sex column
    if 'Sex' in df.columns:
        df['Sex'] = normalize_sex_column(df['Sex'])
    
    # Convert to numeric
    for c in df.columns:
        if c != 'Diagnosis':
            df[c] = pd.to_numeric(df[c], errors='ignore')
    
    # Check for missing features
    missing = [c for c in used_features if c not in df.columns]
    if missing:
        raise ValueError(f"Missing required columns: {missing}")
    
    # Drop rows with NaN in required features
    df_model = df.dropna(subset=used_features).reset_index(drop=True)
    if len(df_model) == 0:
        raise ValueError("No valid rows for inference (all rows have NaN in required features)")
    
    return df_model


# =================== Model Loading ===================
def load_model_and_assets():
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"Model file not found: {MODEL_PATH}")
    if not os.path.exists(SCALER_PATH):
        raise FileNotFoundError(f"Scaler file not found: {SCALER_PATH}")
    if not os.path.exists(FEATURES_PTH):
        raise FileNotFoundError(f"Features file not found: {FEATURES_PTH}")
    
    model = TabNetClassifier()
    model.load_model(MODEL_PATH)
    
    scaler = joblib.load(SCALER_PATH)
    
    with open(FEATURES_PTH, "r") as f:
        used_features = json.load(f)
    
    return model, scaler, used_features


# =================== Medical Report Generation ===================
def _val(row, col):
    try:
        return float(row[col]) if pd.notna(row.get(col, np.nan)) else np.nan
    except Exception:
        return np.nan

def _anemia_phenotype(row):
    mcv  = _val(row, 'MCV')
    mchc = _val(row, 'MCHC')
    rdw  = _val(row, 'RDW')
    
    phenotype = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
    hints = []
    
    if not np.isnan(mcv):
        if mcv < 80:
            phenotype = "Ø£Ù†ÙŠÙ…ÙŠØ§ Ù…ÙŠÙƒØ±ÙˆØ³ÙŠØªÙŠÙƒ (ØºØ§Ù„Ø¨Ù‹Ø§ Ù†Ù‚Øµ Ø§Ù„Ø­Ø¯ÙŠØ¯)"
        elif mcv > 100:
            phenotype = "Ø£Ù†ÙŠÙ…ÙŠØ§ Ù…Ø§ÙƒØ±ÙˆØ³ÙŠØªÙŠÙƒ (Ù‚Ø¯ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ù†Ù‚Øµ B12/ÙÙˆÙ„Ø§Øª Ø£Ùˆ Ø£Ø³Ø¨Ø§Ø¨ Ø£Ø®Ø±Ù‰)"
        else:
            phenotype = "Ø£Ù†ÙŠÙ…ÙŠØ§ Ù†ÙˆØ±Ù…ÙˆØ³ÙŠØªÙŠÙƒ (Ù‚Ø¯ ØªØ±ØªØ¨Ø· Ø¨Ù…Ø±Ø¶ Ù…Ø²Ù…Ù†/Ù†Ø²Ù Ø­Ø§Ø¯/ÙƒÙ„ÙˆÙŠ..)"
    
    if not np.isnan(mchc) and mchc < 32:
        hints.append("Ù‡ÙŠØ¨ÙˆÙƒØ±ÙˆÙ…Ø§ (ÙŠØ¯Ø¹Ù… Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ù‚Øµ Ø§Ù„Ø­Ø¯ÙŠØ¯)")
    if not np.isnan(rdw) and rdw > 14.5:
        hints.append("RDW Ù…Ø±ØªÙØ¹ â†’ ØªØ¨Ø§ÙŠÙ† ÙˆØ§Ø¶Ø­ ÙÙŠ Ø­Ø¬Ù… Ø§Ù„ÙƒØ±ÙŠØ§Øª")
    
    return phenotype, hints

def build_report(row):
    if int(row['Predicted_Anemia']) == 0:
        return (
            "Ø§Ù„Ù†ØªÙŠØ¬Ø©: ØºÙŠØ± Ù…ØµØ§Ø¨ Ø¨Ø§Ù„Ø£Ù†ÙŠÙ…ÙŠØ§ âœ…\n"
            "Ù…Ù„Ø§Ø­Ø¸Ø©: ÙŠÙÙ†ØµØ­ Ø¨Ù†Ù…Ø· Ø­ÙŠØ§Ø© ØµØ­ÙŠØŒ ÙˆØªØ±Ø·ÙŠØ¨ ÙƒØ§ÙÙØŒ ÙˆØ¥Ø¹Ø§Ø¯Ø© CBC Ø¯ÙˆØ±ÙŠÙ‹Ø§ Ø­Ø³Ø¨ ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø·Ø¨ÙŠØ¨."
        )
    
    phenotype, hints = _anemia_phenotype(row)
    hgb = _val(row, 'HGB')
    mcv = _val(row, 'MCV')
    
    base_tests = [
        "Ø¥Ø¹Ø§Ø¯Ø© CBC Ù„Ù„ØªØ£ÙƒÙŠØ¯",
        "Ferritin + Serum Iron + TIBC/Transferrin Saturation",
        "CRP/ESR Ø¹Ù†Ø¯ Ø§Ù„Ø´Ùƒ ÙÙŠ Ù…Ø±Ø¶ Ø§Ù„ØªÙ‡Ø§Ø¨ÙŠ/Ù…Ø²Ù…Ù†",
    ]
    extra_tests = []
    lifestyle = [
        "Ø§Ù„Ø¥ÙƒØ«Ø§Ø± Ù…Ù† Ø§Ù„Ø£Ø·Ø¹Ù…Ø© Ø§Ù„ØºÙ†ÙŠØ© Ø¨Ø§Ù„Ø­Ø¯ÙŠØ¯: ÙƒØ¨Ø¯Ø©ØŒ Ù„Ø­ÙˆÙ… Ø­Ù…Ø±Ø§Ø¡ØŒ Ø¹Ø¯Ø³ØŒ ÙÙˆÙ„ØŒ Ø³Ø¨Ø§Ù†Ø®",
        "ØªÙ†Ø§ÙˆÙ„ ÙÙŠØªØ§Ù…ÙŠÙ† C Ù…Ø¹ Ø§Ù„ÙˆØ¬Ø¨Ø§Øª Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù…ØªØµØ§Øµ Ø§Ù„Ø­Ø¯ÙŠØ¯",
        "ØªØ¬Ù†Ù‘Ø¨ Ø§Ù„Ø´Ø§ÙŠ ÙˆØ§Ù„Ù‚Ù‡ÙˆØ© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¹Ø¯ Ø§Ù„ÙˆØ¬Ø¨Ø§Øª Ø§Ù„ØºÙ†ÙŠØ© Ø¨Ø§Ù„Ø­Ø¯ÙŠØ¯ (ÙŠÙØ¶ÙÙ‘Ù„ Ø¨Ø¹Ø¯ 1â€“2 Ø³Ø§Ø¹Ø©)",
    ]
    
    if not np.isnan(mcv):
        if mcv < 80:
            extra_tests += [
                "ÙØ­Øµ Ù†Ø²Ù Ø®ÙÙŠ Ø¨Ø§Ù„Ø¨Ø±Ø§Ø² (FOBT) Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…Ø± ÙˆØ§Ù„Ø£Ø¹Ø±Ø§Ø¶",
                "ØªÙ‚ÙŠÙŠÙ… Ù†Ø²Ù Ø±Ø­Ù…ÙŠ/Ø³ÙˆØ¡ Ø§Ù…ØªØµØ§Øµ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©",
            ]
        elif mcv > 100:
            extra_tests += [
                "Ù‚ÙŠØ§Ø³ ÙÙŠØªØ§Ù…ÙŠÙ† B12 ÙˆÙÙˆÙ„Ø§Øª",
                "ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØºØ¯Ø© Ø§Ù„Ø¯Ø±Ù‚ÙŠØ© (TSH)",
                "ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ÙƒØ¨Ø¯ (LFTs)",
            ]
        else:
            extra_tests += [
                "ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ÙƒÙÙ„Ù‰ (Creatinine/eGFR)",
                "Ø¨Ø­Ø« Ø¹Ù† Ø£Ù…Ø±Ø§Ø¶ Ù…Ø²Ù…Ù†Ø© Ø£Ùˆ Ù†Ø²Ù Ø­Ø§Ø¯",
            ]
    
    red_flags = [
        "Ø¯ÙˆØ®Ø©/Ø¥ØºÙ…Ø§Ø¡ Ù…ØªÙƒØ±Ø±ØŒ Ø¶ÙŠÙ‚ Ù†ÙØ³ Ø´Ø¯ÙŠØ¯ØŒ Ø£Ù„Ù… ØµØ¯Ø±ÙŠ",
        "Ù‡Ø¨ÙˆØ· Ø´Ø¯ÙŠØ¯ ÙÙŠ Ø§Ù„Ù‡ÙŠÙ…ÙˆØ¬Ù„ÙˆØ¨ÙŠÙ†",
        "Ù†Ø²Ù Ø¸Ø§Ù‡Ø±: Ù‚ÙŠØ¡ Ø¯Ù…ÙˆÙŠØŒ Ø¨Ø±Ø§Ø² Ø£Ø³ÙˆØ¯ØŒ Ù†Ø²Ù Ø±Ø­Ù…ÙŠ Ø´Ø¯ÙŠØ¯",
    ]
    
    lines = []
    lines.append("Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ù…ØµØ§Ø¨ Ø¨Ø§Ù„Ø£Ù†ÙŠÙ…ÙŠØ§ ğŸ©¸")
    if not np.isnan(hgb):
        lines.append(f"Hb: {hgb:.1f} g/dL")
    if not np.isnan(mcv):
        lines.append(f"MCV: {mcv:.1f} fL")
    lines.append(f"Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: {phenotype}")
    if hints:
        lines.append("Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¯Ø§Ø¹Ù…Ø©: " + "Ø› ".join(hints))
    
    lines.append("\nğŸ”¬ ÙØ­ÙˆØµØ§Øª Ù…Ù‚ØªØ±Ø­Ø© (ÙˆÙÙ‚ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø·Ø¨ÙŠØ¨):")
    for t in base_tests + extra_tests:
        lines.append(f"- {t}")
    
    lines.append("\nğŸ½ï¸ Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ù†Ù…Ø· Ø­ÙŠØ§Ø©:")
    for tip in lifestyle:
        lines.append(f"- {tip}")
    
    lines.append("\nğŸš© Ø£Ø¹Ù„Ø§Ù… Ø®Ø·Ø± ØªØ³ØªØ¯Ø¹ÙŠ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø·Ø¨ÙŠØ© Ø¹Ø§Ø¬Ù„Ø©:")
    for f in red_flags:
        lines.append(f"- {f}")
    
    lines.append(
        "\nâš ï¸ ØªÙ†Ø¨ÙŠÙ‡ Ù‡Ø§Ù…: Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¢Ù„ÙŠ Ø§Ø³ØªØ±Ø´Ø§Ø¯ÙŠ ÙˆÙ„Ø§ ÙŠÙØ¹Ø¯ ØªØ´Ø®ÙŠØµÙ‹Ø§ Ù†Ù‡Ø§Ø¦ÙŠÙ‹Ø§."
        " Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø¹Ù„Ø§Ø¬ÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬."
    )
    
    return "\n".join(lines)
